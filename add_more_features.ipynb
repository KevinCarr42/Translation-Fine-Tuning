{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:42:09.064856Z",
     "start_time": "2025-09-09T17:42:07.800744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "import unicodedata\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from create_jsonl import save_jsonl\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# the same dataset after cleaning\n",
    "df_features = pd.read_pickle(\"../Data/df_with_features.pickle\")\n",
    "\n",
    "percentiles = [0.00135, 0.02275, 0.1587, 0.8413, 0.97725, 0.99865]\n",
    "columns = ['50%', '0.1%', '2.3%', '15.9%', '84.1%', '97.7%', '99.9%']"
   ],
   "id": "c002d1ba002a9b01",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# New Feature - number of 1-character words",
   "id": "d15ef3d7d85f2627"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:42:15.029446Z",
     "start_time": "2025-09-09T17:42:09.069865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "actual_one_char_words_fr = ['À', 'A', 'L', 'D', 'N', 'Y', 'M', 'S', 'T', 'à', 'a', 'l', 'd', 'n', 'y', 'm', 's', 't']\n",
    "df_features['one_char_words_fr'] = df_features['fr'].apply(lambda s: sum(len(w) == 1 for w in s.split() if w not in actual_one_char_words_fr))\n",
    "\n",
    "actual_one_char_words_en = ['A', 'I', 'O', 'a', 'o']\n",
    "df_features['one_char_words_en'] = df_features['en'].apply(lambda s: sum(len(w) == 1 for w in s.split() if w not in actual_one_char_words_en))"
   ],
   "id": "de419cccd3d67f4e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cleaning Single Letter Words and Missing Apostrophes (fixing bad OCR)",
   "id": "4650e85b45c2ca52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:42:16.311588Z",
     "start_time": "2025-09-09T17:42:16.236531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make a backup to check before replacements to check results\n",
    "df_features_backup1 = df_features.copy()\n",
    "df_features_backup1 = df_features_backup1[['fr']]\n",
    "df_features_backup1.columns = ['fr_before']"
   ],
   "id": "20eb458d73faf490",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:42:23.522349Z",
     "start_time": "2025-09-09T17:42:16.318478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "always_have_apostrophe = ['L', 'D', 'N', 'M', 'S', 'T', 'l', 'd', 'n', 'm', 's', 't']\n",
    "\n",
    "missing_apostrophe_patterns = []\n",
    "replacement_patterns = []\n",
    "\n",
    "for letter in always_have_apostrophe:\n",
    "  # mid-sentence\n",
    "  missing_apostrophe_patterns.append(f\" {letter} \")\n",
    "  replacement_patterns.append(f\" {letter}'\")\n",
    "\n",
    "  # start of sentence\n",
    "  missing_apostrophe_patterns.append(f\"^{letter} \")\n",
    "  replacement_patterns.append(f\"{letter}'\")\n",
    "\n",
    "n_with_missing = df_features.loc[\n",
    "    df_features['fr'].str.contains('|'.join(missing_apostrophe_patterns), na=False, case=False),\n",
    "].shape[0]\n",
    "n_total = df_features.shape[0]\n",
    "print(f\"{n_with_missing} out of {n_total} sentences are missing apostrophes ({n_with_missing / n_total:.0%})\")"
   ],
   "id": "48d255389ee07061",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431581 out of 778951 sentences are missing apostrophes (55%)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:42:24.001361Z",
     "start_time": "2025-09-09T17:42:23.593668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normal_apostrophe, curved_apostrophe = \"'\", \"’\"\n",
    "\n",
    "print(f\"Normal apostrophe ({normal_apostrophe}): {df_features['fr'].str.count(normal_apostrophe).sum()}\")\n",
    "print(f\"Curved apostrophe ({curved_apostrophe}): {df_features['fr'].str.count(curved_apostrophe).sum()}\")"
   ],
   "id": "b8e5f8f0f7c6ae5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal apostrophe ('): 200432\n",
      "Curved apostrophe (’): 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:42:46.914404Z",
     "start_time": "2025-09-09T17:42:24.084384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clean up these OCR apostrophe issues\n",
    "df_features['fr'] = df_features['fr'].replace(\n",
    "    dict(zip(missing_apostrophe_patterns, replacement_patterns)), \n",
    "    regex=True\n",
    ")\n",
    "\n",
    "n_with_missing = df_features.loc[\n",
    "    df_features['fr'].str.contains('|'.join(missing_apostrophe_patterns), na=False, case=False),\n",
    "].shape[0]\n",
    "n_total = df_features.shape[0]\n",
    "print(f\"after cleaning, {n_with_missing} out of {n_total} sentences are missing apostrophes ({n_with_missing / n_total:.0%})\")"
   ],
   "id": "d714f55174741a99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cleaning, 0 out of 778951 sentences are missing apostrophes (0%)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:42:54.507715Z",
     "start_time": "2025-09-09T17:42:46.979934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# how much difference?\n",
    "\n",
    "before = int(df_features_backup1['fr_before'].apply(lambda s: sum(len(w) == 1 for w in s.split() if w not in actual_one_char_words_fr)).sum())\n",
    "after = int(df_features['fr'].apply(lambda s: sum(len(w) == 1 for w in s.split() if w not in actual_one_char_words_fr)).sum())\n",
    "difference = before - after\n",
    "\n",
    "before, after, difference"
   ],
   "id": "c10745b71b58eed2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291800, 288933, 2867)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# check for missing non-english symbols",
   "id": "e3f6acb414bddd84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:43:06.725084Z",
     "start_time": "2025-09-09T17:42:54.587008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def has_non_english_chars(word):\n",
    "    return bool(re.search(r'[^\\x00-\\x7F]', word))\n",
    "\n",
    "def remove_accents(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "french_words_with_accents = []\n",
    "for sentence in df_features['fr'].to_list():\n",
    "    for word in sentence.split():\n",
    "        clean_word = word.replace('(', '').replace(')', '')\n",
    "        if clean_word.isalpha() and has_non_english_chars(clean_word):\n",
    "            french_words_with_accents.append(clean_word.lower())\n",
    "\n",
    "word_counts = Counter(french_words_with_accents)\n",
    "\n",
    "accent_mapping = pd.DataFrame([\n",
    "    {\n",
    "        'anglicised': remove_accents(word),\n",
    "        'accented': word,\n",
    "        'count': count\n",
    "    }\n",
    "    for word, count in word_counts.items()\n",
    "]).sort_values('count', ascending=False).reset_index(drop=True)"
   ],
   "id": "76c18dfe74490edf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:43:06.938798Z",
     "start_time": "2025-09-09T17:43:06.740611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check accent_mapping for duplicates \n",
    "#  create list of duplicates (to classify as potential quality issues)\n",
    "potential_accent_issues_ambiguous = accent_mapping.loc[accent_mapping.duplicated('anglicised', keep=\"first\"), 'anglicised'].to_list()\n",
    "#  split into non-duplicates (to clean)\n",
    "accent_mapping = accent_mapping.drop_duplicates('anglicised', keep=False)\n",
    "\n",
    "# check for real words in mispelled list\n",
    "spell = SpellChecker(language='fr')\n",
    "#  add all anglicised words that are real french words to another different potentially bad word list\n",
    "potential_accent_issues_real_words = accent_mapping.loc[accent_mapping['anglicised'].isin(spell), 'anglicised'].to_list()\n",
    "#  remove all anglicised words that are real french words \n",
    "accent_mapping = accent_mapping[~accent_mapping['anglicised'].isin(spell)]\n",
    "\n",
    "# NOTE: could there be multiple correct fixes? not in the corpus of data, we've already checked for duplicates, so should be low chances\n",
    "\n",
    "# take the top 1000 most common words that could be cleaned\n",
    "#  add the rest to the potentially bad words\n",
    "potential_accent_issues_uncommon = accent_mapping.tail(accent_mapping.shape[0]-1000).anglicised.to_list()\n",
    "# create dict from remaining words for cleaning\n",
    "accent_mapping = accent_mapping.head(1000)\n",
    "replacement_dict = accent_mapping.set_index('anglicised')['accented'].to_dict()"
   ],
   "id": "1671e02279213849",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:43:07.137433Z",
     "start_time": "2025-09-09T17:43:06.954136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# backup again before replacing\n",
    "\n",
    "df_features_backup2 = df_features.copy()\n",
    "df_features_backup2 = df_features_backup2[['fr']]\n",
    "df_features_backup2.columns = ['fr_before']"
   ],
   "id": "c59e56a7f3327376",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:46:25.509538Z",
     "start_time": "2025-09-09T17:43:07.154644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_replacement_regex(replacement_map):\n",
    "    pattern = r'\\b(' + '|'.join([re.escape(k) for k in replacement_map.keys()]) + r')\\b'\n",
    "    \n",
    "    def replace_func(match):\n",
    "        matched_word = match.group(1)\n",
    "        return replacement_map.get(matched_word, matched_word)\n",
    "    \n",
    "    return pattern, replace_func\n",
    "\n",
    "pattern, replace_func = create_replacement_regex(replacement_dict)\n",
    "df_features['fr'] = df_features['fr'].str.replace(pattern, replace_func, regex=True)"
   ],
   "id": "145566da9b85a2ee",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:46:26.050440Z",
     "start_time": "2025-09-09T17:46:25.528220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# comparisons\n",
    "\n",
    "df_features_compare1 = pd.concat([\n",
    "    df_features, df_features_backup1\n",
    "], axis=1)[['fr', 'fr_before']]\n",
    "df_features_compare1 = df_features_compare1[df_features_compare1.fr != df_features_compare1.fr_before]\n",
    "\n",
    "df_features_compare2 = pd.concat([\n",
    "    df_features, df_features_backup2\n",
    "], axis=1)[['fr', 'fr_before']]\n",
    "\n",
    "df_features_compare2 = df_features_compare2[df_features_compare2.fr != df_features_compare2.fr_before]\n",
    "\n",
    "print(df_features_compare1.shape[0], 'corrections of single letter words')\n",
    "print(df_features_compare2.shape[0], 'corrections of mis-accented words')"
   ],
   "id": "47005072309f8488",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436113 corrections of single letter words\n",
      "5225 corrections of mis-accented words\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:46:26.160606Z",
     "start_time": "2025-09-09T17:46:26.139839Z"
    }
   },
   "cell_type": "code",
   "source": "df_features_compare1.sample().T",
   "id": "c285971a6cc9b083",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                        703470\n",
       "fr         Les auteurs ne peuvent pas affirmer que l'abondance augmente en utilisant la référence de Willia...\n",
       "fr_before  Les auteurs ne peuvent pas affirmer que l abondance augmente en utilisant la référence de Willia..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>703470</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>Les auteurs ne peuvent pas affirmer que l'abondance augmente en utilisant la référence de Willia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_before</th>\n",
       "      <td>Les auteurs ne peuvent pas affirmer que l abondance augmente en utilisant la référence de Willia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:46:26.231876Z",
     "start_time": "2025-09-09T17:46:26.226170Z"
    }
   },
   "cell_type": "code",
   "source": "df_features_compare2.sample().T",
   "id": "ea9be3f89050fea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                        144708\n",
       "fr         On a fait appel aux statistiques de vraisemblance pour évaluer les contributions relatives du te...\n",
       "fr_before  On a fait appel aux statistiques de vraisemblance pour evaluer les contributions relatives du te..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>144708</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>On a fait appel aux statistiques de vraisemblance pour évaluer les contributions relatives du te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_before</th>\n",
       "      <td>On a fait appel aux statistiques de vraisemblance pour evaluer les contributions relatives du te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# create troublesome accented words exclusions",
   "id": "316b1209e2ee6a31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:46:26.271015Z",
     "start_time": "2025-09-09T17:46:26.263813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# potential_accent_issues_ambiguous \n",
    "#  this list is useless, there are so many words that could be accented differently, and many are very common\n",
    "df_features['fr'].head(10).apply(lambda s: sum(w in potential_accent_issues_ambiguous for w in s.split()))"
   ],
   "id": "42286afce05d993",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23\n",
       "1    17\n",
       "2    13\n",
       "3    13\n",
       "4     7\n",
       "5     4\n",
       "6    10\n",
       "7     7\n",
       "8     5\n",
       "9     6\n",
       "Name: fr, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T17:46:26.407811Z",
     "start_time": "2025-09-09T17:46:26.400656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# potential_accent_issues_real_words\n",
    "#  this list is also pretty useless, too many matches\n",
    "df_features['fr'].head(10).apply(lambda s: sum(w in potential_accent_issues_real_words for w in s.split()))"
   ],
   "id": "f25d2aaf2cf407ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    3\n",
       "2    6\n",
       "3    8\n",
       "4    2\n",
       "5    3\n",
       "6    2\n",
       "7    1\n",
       "8    0\n",
       "9    1\n",
       "Name: fr, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:01:00.291458Z",
     "start_time": "2025-09-09T18:01:00.265473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# potential_accent_issues_uncommon \n",
    "#  these look useful - the anglicised fr words with no potential duplicate, that weren't replaced above\n",
    "df_features['fr'].head(10).apply(lambda s: sum(w in potential_accent_issues_uncommon for w in s.split()))"
   ],
   "id": "5fbe4c6cde798de3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: fr, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:26:19.820094Z",
     "start_time": "2025-09-09T18:01:04.993234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# NOTE: very slow, takes 25 min to calculate this\n",
    "df_features['potential_fr_accent_issues'] = df_features['fr'].apply(lambda s: sum(w in potential_accent_issues_uncommon for w in s.split()))"
   ],
   "id": "8f70bc9e0941deeb",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:28:23.619943Z",
     "start_time": "2025-09-09T18:28:23.594371Z"
    }
   },
   "cell_type": "code",
   "source": "pd.DataFrame(df_features['potential_fr_accent_issues'].describe(percentiles=[0.9, 0.99, 0.999])).T",
   "id": "8f8df70ebcaf26d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               count  mean  std  min  50%  90%  99%  99.9%  \\\n",
       "potential_fr_accent_issues 778951.00  0.02 0.14 0.00 0.00 0.00 1.00   1.00   \n",
       "\n",
       "                             max  \n",
       "potential_fr_accent_issues 17.00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>90%</th>\n",
       "      <th>99%</th>\n",
       "      <th>99.9%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>potential_fr_accent_issues</th>\n",
       "      <td>778951.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# save the file",
   "id": "c99f4a7d10f34af4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:28:37.665869Z",
     "start_time": "2025-09-09T18:28:36.507988Z"
    }
   },
   "cell_type": "code",
   "source": "df_features.to_pickle('../Data/df_with_more_features.pickle')",
   "id": "ed97706361a04972",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6003d29b34d2d8c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
